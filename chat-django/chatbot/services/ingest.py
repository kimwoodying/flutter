# chatbot/services/ingest.py
from __future__ import annotations

import json
from pathlib import Path

import faiss

from chatbot.config import get_settings
from chatbot.services.embeddings import embed_texts  # âœ… ê³µìš© ì„ë² ë”© í•¨ìˆ˜ ì‚¬ìš©


def chunk_text(text: str, max_len: int = 400, overlap: int = 50) -> list[str]:
    """
    ê¸´ í…ìŠ¤íŠ¸ë¥¼ RAGìš©ìœ¼ë¡œ ì ë‹¹í•œ ê¸¸ì´ë¡œ ì˜ë¼ì£¼ëŠ” í•¨ìˆ˜.
    ë„ˆë¬´ ì§§ìœ¼ë©´ ê²€ìƒ‰ ì„±ëŠ¥ì´ ë–¨ì–´ì§€ê³ , ë„ˆë¬´ ê¸¸ë©´ í† í° ë‚­ë¹„ë¼ì„œ 300~500ì ì •ë„ ì¶”ì²œ.
    """
    text = text.replace("\n", " ").strip()
    if len(text) <= max_len:
        return [text]

    chunks: list[str] = []
    start = 0
    while start < len(text):
        end = start + max_len
        chunks.append(text[start:end])
        start = end - overlap  # ì¼ì • ë¶€ë¶„ ê²¹ì¹˜ê²Œ

    return [c.strip() for c in chunks if c.strip()]


def main() -> None:
    settings = get_settings()

    raw_dir = Path(__file__).parent.parent / "data" / "raw"
    if not raw_dir.exists():
        raise FileNotFoundError(f"raw í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤: {raw_dir.resolve()}")

    texts: list[str] = []
    metadata: list[dict] = []

    print(f"ğŸ“‚ TXT ë¡œë”© ì¤‘... ({raw_dir.resolve()})")
    for txt_file in raw_dir.glob("*.txt"):
        content = txt_file.read_text(encoding="utf-8")

        # ì§€ê¸ˆì²˜ëŸ¼ í•˜ë‚˜ì˜ íŒŒì¼ ì•ˆì— --- ë¸”ë¡ ì—¬ëŸ¬ ê°œê°€ ìˆì–´ë„
        # ì „ì²´ë¥¼ í†µìœ¼ë¡œ chunk_textì— ë„˜ê¸°ë©´ ì•Œì•„ì„œ ì˜ë ¤ì„œ ë“¤ì–´ê°
        chunks = chunk_text(content)

        for i, chunk in enumerate(chunks):
            texts.append(chunk)
            metadata.append(
                {
                    "id": len(metadata),
                    "source": txt_file.name,
                    "chunk": i,
                    "text": chunk,
                }
            )

    if not texts:
        raise ValueError("raw í´ë”ì— .txt ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë³‘ì› ì•ˆë‚´ txtë¥¼ ë„£ì–´ì£¼ì„¸ìš”.")

    print(f"ğŸ§  ì„ë² ë”© ìƒì„± ì¤‘... (ì´ {len(texts)}ê°œ chunk)")
    # âœ… ê³µìš© ì„ë² ë”© í•¨ìˆ˜ ì‚¬ìš© (SentenceTransformer ì§ì ‘ ìƒì„± X)
    vectors = embed_texts(texts)

    import numpy as np
    vectors = np.asarray(vectors, dtype="float32")

    dim = vectors.shape[1]
    index = faiss.IndexFlatL2(dim)
    index.add(vectors)

    index_path = Path(settings.faiss_index_path)
    metadata_path = Path(settings.metadata_path)

    index_path.parent.mkdir(parents=True, exist_ok=True)
    metadata_path.parent.mkdir(parents=True, exist_ok=True)

    faiss.write_index(index, str(index_path))
    metadata_path.write_text(
        json.dumps(metadata, ensure_ascii=False, indent=2),
        encoding="utf-8",
    )

    print("âœ… FAISS ì¸ë±ìŠ¤ ì €ì¥ ì™„ë£Œ:", index_path.resolve())
    print("âœ… ë©”íƒ€ë°ì´í„° ì €ì¥ ì™„ë£Œ:", metadata_path.resolve())


if __name__ == "__main__":
    main()
